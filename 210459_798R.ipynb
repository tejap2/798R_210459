{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5cJaBkZOORVqbGZ4Mz/fo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fW1Etgz16ONY"},"outputs":[],"source":["from google.colab import drive\n","import numpy as np\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load ECG signals and labels from your Google Drive (update path as needed)\n","ecg_signals = np.load('/content/drive/MyDrive/ECG_Project/ecg_signals.npy')\n","ecg_labels = np.load('/content/drive/MyDrive/ECG_Project/ecg_labels.npy')\n","\n","print(f\"ECG Signals Shape: {ecg_signals.shape}\")\n","print(f\"ECG Labels Shape: {ecg_labels.shape}\")\n"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import scipy.stats as stats\n","from scipy.fftpack import fft\n","from scipy.signal import find_peaks\n","\n","# Function to extract features from a single ECG signal\n","def extract_features(ecg_signal):\n","    features = {}\n","\n","    # Statistical features\n","    features['mean'] = np.mean(ecg_signal)\n","    features['variance'] = np.var(ecg_signal)\n","    features['kurtosis'] = stats.kurtosis(ecg_signal)\n","    features['skewness'] = stats.skew(ecg_signal)\n","\n","    # Frequency domain features (e.g., Spectral Entropy)\n","    spectral_entropy = -np.sum(fft(ecg_signal) * np.log2(fft(ecg_signal)))\n","    features['spectral_entropy'] = spectral_entropy\n","\n","    # Morphological features (RR intervals, SDNN, RMSSD)\n","    peaks, _ = find_peaks(ecg_signal, distance=300)  # Example peak detection\n","    rr_intervals = np.diff(peaks)\n","    features['mean_rr'] = np.mean(rr_intervals)\n","    features['sdnn'] = np.std(rr_intervals)\n","    features['rmssd'] = np.sqrt(np.mean(np.square(np.diff(rr_intervals))))\n","\n","    return features\n","\n","# Process multiple ECG signals and save the features to a CSV\n","def process_ecg_dataset(ecg_signals, labels, output_file='ecg_features.csv'):\n","    features_list = []\n","\n","    for i, ecg_signal in enumerate(ecg_signals):\n","        features = extract_features(ecg_signal)\n","        features['label'] = labels[i]\n","        features_list.append(features)\n","\n","    features_df = pd.DataFrame(features_list)\n","    features_df.to_csv(output_file, index=False)\n","    print(f\"Features saved to {output_file}\")\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    process_ecg_dataset(ecg_signals, ecg_labels, output_file='/content/ecg_features.csv')\n"],"metadata":{"id":"74iTZ83B85R0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Load the extracted features dataset\n","data = pd.read_csv('/content/ecg_features.csv')\n","X = data.drop('label', axis=1).values  # Features\n","y = data['label'].values  # Labels (0: low stress, 1: medium stress, 2: high stress)\n","\n","# Split the dataset into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Reshape the data for CNN input\n","X_train = X_train.reshape(-1, X_train.shape[1], 1)\n","X_val = X_val.reshape(-1, X_val.shape[1], 1)\n","\n","# Define the CNN model\n","def create_cnn_model(input_shape):\n","    model = Sequential()\n","    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(3, activation='softmax'))\n","\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Create the model\n","input_shape = (X_train.shape[1], 1)\n","model = create_cnn_model(input_shape)\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32)\n","\n","# Save the model\n","model.save('/content/stress_recognition_model.h5')\n","\n","print(\"Training Complete\")\n","\n"],"metadata":{"id":"BSjK-4oe87yH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","import pandas as pd\n","\n","# Load the trained model\n","model = tf.keras.models.load_model('/content/stress_recognition_model.h5')\n","\n","# Load the test dataset\n","test_data = pd.read_csv('/content/ecg_test_features.csv')  # Ensure you have the test feature file\n","X_test = test_data.drop('label', axis=1).values\n","y_test = test_data['label'].values\n","\n","# Reshape the test data for the CNN model\n","X_test = X_test.reshape(-1, X_test.shape[1], 1)\n","\n","# Make predictions\n","y_pred = model.predict(X_test)\n","y_pred = y_pred.argmax(axis=1)  # Get the class with highest probability\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Print classification report\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred, target_names=[\"Low Stress\", \"Medium Stress\", \"High Stress\"]))\n","\n","# Print confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n"],"metadata":{"id":"yagCm8nq93lX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Load test results (Predictions vs Ground Truth)\n","results = pd.read_csv('/content/test_results.csv')  # Columns ['y_true', 'y_pred']\n","\n","# Plot Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Low Stress', 'Medium Stress', 'High Stress'], yticklabels=['Low Stress', 'Medium Stress', 'High Stress'])\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Plot Feature Boxplots\n","def plot_feature_boxplots():\n","    data = pd.read_csv('/content/ecg_features.csv')  # Ensure you have the feature file\n","    plt.figure(figsize=(12, 8))\n","    sns.boxplot(data=data.drop('label', axis=1))\n","    plt.title('Boxplot of ECG Features')\n","    plt.xticks(rotation=90)\n","    plt.show()\n","\n","# Classification report\n","def classification_analysis(y_true, y_pred):\n","    print(classification_report(y_true, y_pred, target_names=['Low Stress', 'Medium Stress', 'High Stress']))\n","\n","if __name__ == \"__main__\":\n","    y_true = results['y_true']\n","    y_pred = results['y_pred']\n","\n","    plot_confusion_matrix(y_true, y_pred)\n","    plot_feature_boxplots()\n","    classification_analysis(y_true, y_pred)\n"],"metadata":{"id":"bD5UEKVgC2Ux"},"execution_count":null,"outputs":[]}]}